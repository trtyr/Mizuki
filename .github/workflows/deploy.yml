name: Full Sync to COS using Python SDK
on: [push]
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Install Node.js
        uses: actions/setup-node@v3
        with:
          node-version: "20"

      - name: Install pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 8

      - name: Install dependencies
        run: pnpm install

      - name: Build Astro project
        run: pnpm run build

      - name: Install Tencent COS SDK
        run: sudo pip3 install cos-python-sdk-v5

      - name: Full Sync to COS using Python SDK
        env:
          SECRET_ID: ${{ secrets.SECRETID }}
          SECRET_KEY: ${{ secrets.SECRETKEY }}
          BUCKET: ${{ secrets.BUCKET }}
          REGION: ${{ secrets.REGION }}
        run: |
          python3 << 'EOF'
          import os
          import sys
          import logging
          from qcloud_cos import CosConfig
          from qcloud_cos import CosS3Client
          from qcloud_cos import CosServiceError
          from qcloud_cos import CosClientError
          import time
          import threading
          from concurrent.futures import ThreadPoolExecutor, as_completed

          # 配置日志
          logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
          logger = logging.getLogger(__name__)

          # 配置COS客户端
          try:
              config = CosConfig(
                  Region=os.environ['REGION'],
                  SecretId=os.environ['SECRET_ID'],
                  SecretKey=os.environ['SECRET_KEY']
              )
              client = CosS3Client(config)
              bucket = os.environ['BUCKET']
              logger.info(f"COS客户端初始化成功，存储桶: {bucket}")
          except Exception as e:
              logger.error(f"COS客户端初始化失败: {e}")
              sys.exit(1)

          # 线程安全的统计类
          class SyncStats:
              def __init__(self):
                  self.uploaded = 0
                  self.deleted = 0
                  self.failed = 0
                  self.lock = threading.Lock()

              def increment(self, field):
                  with self.lock:
                      if field == 'uploaded':
                          self.uploaded += 1
                      elif field == 'deleted':
                          self.deleted += 1
                      elif field == 'failed':
                          self.failed += 1

          stats = SyncStats()

          # 直接上传文件，不检查是否存在
          def upload_file(local_path, cos_key, max_retries=2):
              for attempt in range(max_retries):
                  try:
                      logger.info(f"上传文件: {local_path} -> {cos_key} (尝试 {attempt + 1}/{max_retries})")

                      # 根据文件大小选择上传策略
                      file_size = os.path.getsize(local_path)

                      if file_size > 5 * 1024 * 1024:  # 大于5MB使用分片上传
                          logger.info(f"大文件分片上传: {cos_key} ({file_size/1024/1024:.2f}MB)")
                          response = client.upload_file(
                              Bucket=bucket,
                              LocalFilePath=local_path,
                              Key=cos_key,
                              PartSize=1 * 1024 * 1024,  # 1MB分片
                              MAXThread=3  # 限制并发数
                          )
                      else:  # 小文件直接上传
                          response = client.upload_file(
                              Bucket=bucket,
                              LocalFilePath=local_path,
                              Key=cos_key
                          )

                      logger.info(f"上传成功: {cos_key}")
                      stats.increment('uploaded')
                      return True

                  except CosServiceError as e:
                      logger.error(f"上传失败 (CosServiceError): {cos_key} - {e}")
                      if attempt == max_retries - 1:
                          stats.increment('failed')
                          return False
                      time.sleep(1)

                  except CosClientError as e:
                      logger.error(f"上传失败 (CosClientError): {cos_key} - {e}")
                      if attempt == max_retries - 1:
                          stats.increment('failed')
                          return False
                      time.sleep(1)

                  except Exception as e:
                      logger.error(f"上传失败 (Exception): {cos_key} - {e}")
                      if attempt == max_retries - 1:
                          stats.increment('failed')
                          return False
                      time.sleep(1)

              return False

          # 删除COS中的文件
          def delete_file(cos_key, max_retries=2):
              for attempt in range(max_retries):
                  try:
                      logger.info(f"删除文件: {cos_key} (尝试 {attempt + 1}/{max_retries})")

                      client.delete_object(
                          Bucket=bucket,
                          Key=cos_key
                      )

                      logger.info(f"删除成功: {cos_key}")
                      stats.increment('deleted')
                      return True

                  except CosServiceError as e:
                      logger.error(f"删除失败 (CosServiceError): {cos_key} - {e}")
                      if attempt == max_retries - 1:
                          stats.increment('failed')
                          return False
                      time.sleep(1)

                  except Exception as e:
                      logger.error(f"删除失败 (Exception): {cos_key} - {e}")
                      if attempt == max_retries - 1:
                          stats.increment('failed')
                          return False
                      time.sleep(1)

              return False

          # 并发上传函数
          def upload_files_concurrent(file_list, max_workers=3):
              logger.info(f"开始并发上传 {len(file_list)} 个文件，并发数: {max_workers}")

              with ThreadPoolExecutor(max_workers=max_workers) as executor:
                  # 提交所有上传任务
                  future_to_file = {
                      executor.submit(upload_file, local_path, cos_key): (local_path, cos_key)
                      for local_path, cos_key in file_list
                  }

                  # 处理完成的任务
                  for future in as_completed(future_to_file):
                      local_path, cos_key = future_to_file[future]
                      try:
                          success = future.result()
                          if not success:
                              logger.error(f"文件上传失败: {cos_key}")
                      except Exception as e:
                          logger.error(f"处理上传任务时发生异常: {cos_key} - {e}")

          # 并发删除函数
          def delete_files_concurrent(file_list, max_workers=5):
              logger.info(f"开始并发删除 {len(file_list)} 个文件，并发数: {max_workers}")

              with ThreadPoolExecutor(max_workers=max_workers) as executor:
                  # 提交所有删除任务
                  future_to_file = {
                      executor.submit(delete_file, cos_key): cos_key
                      for cos_key in file_list
                  }

                  # 处理完成的任务
                  for future in as_completed(future_to_file):
                      cos_key = future_to_file[future]
                      try:
                          success = future.result()
                          if not success:
                              logger.error(f"文件删除失败: {cos_key}")
                      except Exception as e:
                          logger.error(f"处理删除任务时发生异常: {cos_key} - {e}")

          # 获取本地所有文件
          def get_local_files(local_dir):
              logger.info(f"扫描本地目录: {local_dir}")
              local_files = set()

              for root, dirs, files in os.walk(local_dir):
                  for file in files:
                      local_path = os.path.join(root, file)
                      relative_path = os.path.relpath(local_path, local_dir)
                      cos_path = os.path.join('/', relative_path).replace('\\', '/')
                      local_files.add(cos_path)

              logger.info(f"本地文件数量: {len(local_files)}")
              return local_files

          # 获取COS所有文件
          def get_cos_files(cos_dir):
              logger.info(f"扫描COS目录: {cos_dir}")
              cos_files = set()

              try:
                  paginator = client.get_paginator('list_objects_v2')
                  page_iterator = paginator.paginate(
                      Bucket=bucket,
                      Prefix=cos_dir,
                      MaxKeys=1000
                  )

                  for page in page_iterator:
                      if 'Contents' in page:
                          for obj in page['Contents']:
                              cos_key = obj['Key']
                              # 跳过目录本身（以/结尾的空目录）
                              if cos_key != cos_dir or not cos_key.endswith('/'):
                                  cos_files.add(cos_key)

                  logger.info(f"COS文件数量: {len(cos_files)}")
                  return cos_files

              except Exception as e:
                  logger.error(f"获取COS文件列表失败: {e}")
                  return set()

          # 完全同步函数
          def full_sync(local_dir, cos_dir):
              logger.info("开始完全同步...")

              # 获取本地和COS的文件列表
              local_files = get_local_files(local_dir)
              cos_files = get_cos_files(cos_dir)

              # 计算需要上传和删除的文件
              files_to_upload = []
              files_to_delete = []

              for cos_key in local_files:
                  local_path = os.path.join(local_dir, cos_key.lstrip('/'))
                  files_to_upload.append((local_path, cos_key))

              for cos_key in cos_files:
                  if cos_key not in local_files:
                      files_to_delete.append(cos_key)

              logger.info(f"需要上传的文件: {len(files_to_upload)}")
              logger.info(f"需要删除的文件: {len(files_to_delete)}")

              # 先上传文件
              if files_to_upload:
                  logger.info("开始上传文件...")
                  # 分批上传
                  batch_size = 15
                  for i in range(0, len(files_to_upload), batch_size):
                      batch = files_to_upload[i:i + batch_size]
                      logger.info(f"上传批次 {i//batch_size + 1}/{(len(files_to_upload) + batch_size - 1)//batch_size}")
                      upload_files_concurrent(batch, max_workers=3)

                      # 批次间短暂休息
                      if i + batch_size < len(files_to_upload):
                          time.sleep(1)

              # 再删除文件
              if files_to_delete:
                  logger.info("开始删除文件...")
                  # 分批删除
                  batch_size = 20
                  for i in range(0, len(files_to_delete), batch_size):
                      batch = files_to_delete[i:i + batch_size]
                      logger.info(f"删除批次 {i//batch_size + 1}/{(len(files_to_delete) + batch_size - 1)//batch_size}")
                      delete_files_concurrent(batch, max_workers=5)

                      # 批次间短暂休息
                      if i + batch_size < len(files_to_delete):
                          time.sleep(0.5)

          # 主执行流程
          try:
              logger.info("开始完全同步到腾讯云COS...")

              # 执行完全同步
              full_sync('./dist', '/')

              # 输出最终统计信息
              logger.info("=" * 50)
              logger.info("同步完成！")
              logger.info(f"成功上传: {stats.uploaded}")
              logger.info(f"成功删除: {stats.deleted}")
              logger.info(f"失败操作: {stats.failed}")
              logger.info("=" * 50)

              if stats.failed > 0:
                  logger.warning(f"有 {stats.failed} 个操作失败，请检查日志")
                  sys.exit(1)
              else:
                  logger.info("同步完全成功！云端与本地完全一致！")

          except Exception as e:
              logger.error(f"同步过程中发生未预期的错误: {e}")
              sys.exit(1)
          EOF
